{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86e68ebc-daa5-4d9c-b512-8296ecbf60dc",
   "metadata": {},
   "source": [
    "#### Instructions:  \n",
    "1. Libraries allowed: **Python basic libraries, numpy, pandas, scikit-learn (only for data processing), pytorch, and ClearML.**\n",
    "2. Show all outputs.\n",
    "3. Submit jupyter notebook and a pdf export of the notebook. Check canvas for detail instructions for the report. \n",
    "4. Below are the questions/steps that you need to answer. Add as many cells as needed. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c2cc5a-a1cb-469d-9d4d-18d14938fe83",
   "metadata": {},
   "source": [
    "## Task 2: Finetuning a pretrained NN\r\n",
    "Do transfer learning with ResNet18 and compare peforamnce with the hyperparamter-tuned network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "88555b95-448b-4dac-90b6-da7c33a6c977",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms,models\n",
    "from torch.utils.data import DataLoader, random_split, Subset\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3540238b-c0e8-4288-8416-be803d2c0b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = r\"D:\\Semester 3\\Deep Learning\\Assignments\\Project1\\Dataset\\organized_dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "13f22839-01cd-4a01-a185-9b8ef153f2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a5da74db-cffe-4126-83ed-7ce81329880f",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    'train': datasets.ImageFolder(root=f\"{data_dir}/train\", transform=data_transforms['train']),\n",
    "    'val': datasets.ImageFolder(root=f\"{data_dir}/val\", transform=data_transforms['val']),\n",
    "    'test': datasets.ImageFolder(root=f\"{data_dir}/test\", transform=data_transforms['test'])    \n",
    "}\n",
    "\n",
    "# Create dataloaders\n",
    "dataloaders = {\n",
    "    'train': DataLoader(datasets['train'], batch_size=32, shuffle=True, num_workers=4),\n",
    "    'val': DataLoader(datasets['val'], batch_size=32, shuffle=False, num_workers=4),\n",
    "    'test': DataLoader(datasets['test'], batch_size=32, shuffle=True, num_workers=4)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9201b217-abf3-4537-8b73-8f458b8249ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(datasets['train'].classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4c071e9-b53a-4720-9ea5-95266bc4b93c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "----------\n",
      "Train Loss: 0.4774 Acc: 0.8348\n",
      "Val Loss: 0.7619 Acc: 0.7929\n",
      "Epoch 2/10\n",
      "----------\n",
      "Train Loss: 0.3486 Acc: 0.8991\n",
      "Val Loss: 0.5386 Acc: 0.8143\n",
      "Epoch 3/10\n",
      "----------\n",
      "Train Loss: 0.1892 Acc: 0.9473\n",
      "Val Loss: 0.2407 Acc: 0.9143\n",
      "Epoch 4/10\n",
      "----------\n",
      "Train Loss: 0.1079 Acc: 0.9616\n",
      "Val Loss: 0.0564 Acc: 0.9929\n",
      "Epoch 5/10\n",
      "----------\n",
      "Train Loss: 0.0680 Acc: 0.9795\n",
      "Val Loss: 0.1849 Acc: 0.9357\n",
      "Epoch 6/10\n",
      "----------\n",
      "Train Loss: 0.0292 Acc: 0.9938\n",
      "Val Loss: 0.0903 Acc: 0.9714\n",
      "Epoch 7/10\n",
      "----------\n",
      "Train Loss: 0.0423 Acc: 0.9875\n",
      "Val Loss: 0.2959 Acc: 0.9214\n",
      "Epoch 8/10\n",
      "----------\n",
      "Train Loss: 0.1192 Acc: 0.9670\n",
      "Val Loss: 0.1656 Acc: 0.9357\n",
      "Epoch 9/10\n",
      "----------\n",
      "Train Loss: 0.0902 Acc: 0.9750\n",
      "Val Loss: 1.3636 Acc: 0.7357\n",
      "Epoch 10/10\n",
      "----------\n",
      "Train Loss: 0.0787 Acc: 0.9705\n",
      "Val Loss: 0.2056 Acc: 0.9500\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet18(pretrained=True)\n",
    "num_classes = len(datasets['train'].classes)\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    print(\"-\" * 10)\n",
    "    \n",
    "    for phase in ['train', 'val']:\n",
    "        if phase == 'train':\n",
    "            model.train()\n",
    "        else:\n",
    "            model.eval()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        for inputs, labels in dataloaders[phase]:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        epoch_loss = running_loss / len(datasets[phase])\n",
    "        epoch_acc = running_corrects.double() / len(datasets[phase])\n",
    "\n",
    "        print(f\"{phase.capitalize()} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
    "\n",
    "torch.save(model.state_dict(), \"resnet18_finetuned.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dfc68fb8-cbb1-431d-9592-3d8f67c49259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics on Test Data:\n",
      "Accuracy: 0.8857\n",
      "Precision: 0.8940\n",
      "Recall: 0.8857\n",
      "F1 Score: 0.8867\n"
     ]
    }
   ],
   "source": [
    "model.eval() \n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "with torch.no_grad():\n",
    "    for images, labels in dataloaders['test']:  # Use the test DataLoader\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "precision = precision_score(all_labels, all_preds, average=\"weighted\")\n",
    "recall = recall_score(all_labels, all_preds, average=\"weighted\")\n",
    "f1 = f1_score(all_labels, all_preds, average=\"weighted\")\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Evaluation Metrics on Test Data:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1eb04a4-7cbb-4d89-a70d-f1ae5c7c8fe3",
   "metadata": {},
   "source": [
    "### Discussion\r\n",
    "Provide a comparative analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e77ec1-23fb-47dc-9f9c-402b672f425e",
   "metadata": {},
   "source": [
    "The pretrained model has demonstrated superior performance in terms of accuracy, precision, recall, and F1 score compared to model tuned through hyperparameter optimization.\n",
    "\n",
    "In this part, the metrics achieved by the pretrained model—accuracy of 88.57%, precision of 89.40%, recall of 88.57%, and F1 score of 88.67%—indicate a strong and balanced performance. \n",
    "\n",
    "Given these results, it’s evident that the pretrained model’s inherent optimization outperforms hyperparameter-tuned models for this task. This highlights the advantage of leveraging pretrained weights for achieving high performance without extensive tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fbdfb0-89cd-46ca-9ea4-f78510d0408b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
